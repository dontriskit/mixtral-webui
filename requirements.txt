accelerate==0.25.*
colorama
datasets
einops
exllamav2==0.0.10
gradio==3.50.*
markdown
numpy==1.24.*
optimum==1.15.*
pandas
peft==0.7.*
Pillow>=9.5.0
pyyaml
requests
safetensors==0.4.1
scipy
sentencepiece
tensorboard
transformers==4.36.*
tqdm
wandb

git+https://github.com/oobabooga/torch-grammar.git

# bitsandbytes
bitsandbytes==0.41.1
# CUDA wheels
https://github.com/jllllll/AutoGPTQ/releases/download/v0.5.1/auto_gptq-0.5.1+cu121-cp310-cp310-linux_x86_64.whl
https://github.com/jllllll/exllama/releases/download/0.0.18/exllama-0.0.18+cu121-cp310-cp310-linux_x86_64.whl
https://github.com/turboderp/exllamav2/releases/download/v0.0.10/exllamav2-0.0.10+cu121-cp310-cp310-linux_x86_64.whl
https://github.com/Dao-AILab/flash-attention/releases/download/v2.3.4/flash_attn-2.3.4+cu122torch2.1cxx11abiFALSE-cp310-cp310-linux_x86_64.whl
https://github.com/jllllll/GPTQ-for-LLaMa-CUDA/releases/download/0.1.1/gptq_for_llama-0.1.1+cu121-cp310-cp310-linux_x86_64.whl
https://github.com/jllllll/ctransformers-cuBLAS-wheels/releases/download/AVX2/ctransformers-0.2.27+cu121-py3-none-any.whl
autoawq==0.1.7; platform_system == "Linux" or platform_system == "Windows"
